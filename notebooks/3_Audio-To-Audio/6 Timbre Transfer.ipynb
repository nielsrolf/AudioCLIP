{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Timbre Transfer",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1Ej7kOE1JlqT/Iyr1ncNM"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_qxhiZSDcvb"
      },
      "source": [
        "Timbre Transfer using DDSP\n",
        "\n",
        "Here, you can play any instrument with your voice: sing the melody or mimic the sound you would like to play, and upload a sample of the real instrument. Both audios should be monophonic - that means that there are no background noises and only one note is being played at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZHE_rcsdomO"
      },
      "source": [
        "# Melody Input\n",
        "audio_melody = 'https://pandasdb-ddsp-demo.s3.eu-central-1.amazonaws.com/.pandas_db_files/samples/vozes_trimmed.mp3' #@param {type: \"string\"}\n",
        "\n",
        "# Timbre Input\n",
        "audio_timbre = 'https://pandasdb-ddsp-demo.s3.eu-central-1.amazonaws.com/.pandas_db_files/samples/urmp_test/AuSep_4_sax_27_King.wav' #@param {type: \"string\"}\n",
        "\n",
        "fine_tune_steps = 20 #@param {type: \"integer\"}\n",
        "output_path = \"/content/output\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbFA-gVdsrYO"
      },
      "source": [
        "from uuid import uuid4\n",
        "# Maybe download data\n",
        "def maybe_download(filepath):\n",
        "  if filepath.startswith(\"http\"):\n",
        "    new_name = filepath.split(\"/\")[-1]\n",
        "    !wget -N {filepath} -O {new_name}\n",
        "    return new_name\n",
        "  return filepath\n",
        "melody = maybe_download(audio_melody)\n",
        "timbre = maybe_download(audio_timbre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5rcRDpsOGdB"
      },
      "source": [
        "#@title #Install and Import\n",
        "!pip install git+git://github.com/nielsrolf/pandas_db &> /dev/null\n",
        "!pip install tensorflow==2.4 &> /dev/null\n",
        "!pip install apache-beam avro-python3==1.9.0 &> /dev/null\n",
        "!pip install --upgrade git+git://github.com/nielsrolf/ddsp &> /dev/null\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "#@markdown Install ddsp, define some helper functions, and download the model. This transfers a lot of data and _should take a minute or two_.\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "\n",
        "\n",
        "# Ignore a bunch of deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from ddsp.training.file_api import TrainedModelFileAPI\n",
        "from ddsp.training.tuned import TunedAEFileApi\n",
        "from ddsp.colab.colab_utils import play\n",
        "\n",
        "# Helper Functions\n",
        "sample_rate = 16000\n",
        "\n",
        "\n",
        "from ddsp.training.data_preparation.prepare_tfrecord_lib import _load_audio\n",
        "\n",
        "\n",
        "def load_audio_file(file):\n",
        "  print(str(file))\n",
        "  wav = _load_audio(file, sample_rate)\n",
        "  return wav['audio']\n",
        "\n",
        "\n",
        "def play_file(file):\n",
        "  wav = load_audio_file(file)\n",
        "  play(wav)\n",
        "\n",
        "\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5GKibxm1Tcv"
      },
      "source": [
        "#@title #Download model and sample wav files\n",
        "!wget -N https://pandasdb-ddsp-demo.s3.eu-central-1.amazonaws.com/dashboard/improved_baseline_ae_combined_train.zip\n",
        "!unzip improved_baseline_ae_combined_train.zip\n",
        "model_dir = \"improved_baseline_ae_combined_train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WNwraTEBA1U"
      },
      "source": [
        "## Timbre Transfer with fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTn3imlZci4"
      },
      "source": [
        "\"\"\"\n",
        "Wrapper for an autoencoder that fine tunes on a batch\n",
        "whenever it needs to extract z\n",
        "\"\"\"\n",
        "import functools\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "import gin\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from ddsp.training import train_util\n",
        "from ddsp.training.data_preparation.prepare_tfrecord_lib import (\n",
        "    _add_f0_estimate, _load_audio, add_loudness, add_loudness_new,\n",
        "    split_example)\n",
        "from ddsp.training.file_api import TrainedModelFileAPI\n",
        "from ddsp.training.models import get_model\n",
        "from ddsp.training.trainers import Trainer\n",
        "\n",
        "\n",
        "@functools.lru_cache(4)\n",
        "def preprocess_file(file):\n",
        "  ex = _load_audio(file, 16000)\n",
        "  ex = _add_f0_estimate(ex, 16000, 250)\n",
        "  ex = add_loudness(ex, 16000, 250)\n",
        "  ex = add_loudness_new(ex,  16000, 250)\n",
        "  #sample_rate, frame_rate, window_secs, hop_secs\n",
        "  ex = list(split_example(ex, 16000, 250, 4, 4))\n",
        "  return ex\n",
        "\n",
        "\n",
        "def preprocess_files(files, batch_size=2):\n",
        "  try:\n",
        "    full_batch = {}\n",
        "    for file in files:\n",
        "      examples = preprocess_file(file)\n",
        "      for example in examples:\n",
        "        for k, v in example.items():\n",
        "          full_batch[k] = full_batch.get(k, []) + [v]\n",
        "    permutation = np.random.permutation((len(full_batch['audio'])//batch_size)*batch_size)\n",
        "    for k, v in full_batch.items():\n",
        "      full_batch[k] = np.array(full_batch[k])[permutation].reshape(\n",
        "                              [-1, batch_size] + list(full_batch[k][0].shape))\n",
        "  except Exception as e:\n",
        "    print(\"Is your audio too short for the required batch_size? E.g. 16s for batch_size=2\")\n",
        "    raise e\n",
        "  return full_batch\n",
        "\n",
        "\n",
        "def get_trained_model(model_dir):\n",
        "  gin_file = os.path.join(model_dir, \"operative_config-0.gin\")\n",
        "  # Parse gin config,\n",
        "  with gin.unlock_config():\n",
        "    gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "\n",
        "  ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if \"ckpt\" in f]\n",
        "  step_of = lambda f: int(f.split(\".\")[0].split(\"-\")[1])\n",
        "  latest = max([step_of(f) for f in ckpt_files])\n",
        "  ckpt_name = [i for i in ckpt_files if step_of(i) == latest][0].split(\".\")[0]\n",
        "  ckpt = os.path.join(model_dir, ckpt_name)\n",
        "\n",
        "  model = get_model()\n",
        "  model.restore(ckpt)\n",
        "  return model, ckpt\n",
        "\n",
        "\n",
        "def split_batches(batches):\n",
        "  num_test_batches =len(batches['audio'])//2\n",
        "  test_sec = num_test_batches*len(batches['audio'][0])*4\n",
        "  print(f\"The first {test_sec} seconds are not used for fine-tuning\")\n",
        "  batches_train = {k: v[num_test_batches:] for k, v in batches.items()}\n",
        "  batches_test = {k: tf.reshape(v[:num_test_batches], [-1] + list(v.shape[2:])) for k, v in batches.items()}\n",
        "  return batches_train, batches_test, test_sec\n",
        "\n",
        "\n",
        "class TunedAEFileApi():\n",
        "  \"\"\"Similar to TrainedModelFileAPI, but does fine tuning on the\n",
        "  target timbre before prediction\"\"\"\n",
        "  def __init__(self, model_dir, steps=fine_tune_steps):\n",
        "    self.model_dir = model_dir\n",
        "    self.steps = steps\n",
        "\n",
        "  def fine_tune(self, files, tmpdir):\n",
        "    batches = preprocess_files(files)\n",
        "    model, ckpt = get_trained_model(self.model_dir)\n",
        "    strategy = train_util.get_strategy()\n",
        "    trainer = Trainer(model, strategy, checkpoints_to_keep=1)\n",
        "    trainer.restore(ckpt)\n",
        "    for i in range(self.steps):\n",
        "      batch = {k: v[i % len(v)] for k, v in batches.items()}\n",
        "      trainer.train_step(batch)\n",
        "    trainer.save(tmpdir)\n",
        "    shutil.copy(f\"{self.model_dir}/operative_config-0.gin\",\n",
        "                f\"{tmpdir}/operative_config-0.gin\")\n",
        "    return model\n",
        "\n",
        "  def get_finetuned_file_api(self, files, tmpdir): \n",
        "    self.fine_tune(files, tmpdir)\n",
        "    if self.steps == 0:\n",
        "      tmpdir = self.model_dir\n",
        "    return TrainedModelFileAPI(tmpdir)\n",
        "\n",
        "  def reconstruct(self, audio):\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "      return self.get_finetuned_file_api([audio], tmpdir).reconstruct(audio)\n",
        "\n",
        "  def transfer(self, melody, timbre):\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "      return self.get_finetuned_file_api([timbre], tmpdir).transfer(melody, timbre)\n",
        "\n",
        "  def continuous_interpolation(self, melody, final_timbre):\n",
        "    return self.get_finetuned_file_api([melody, final_timbre]).continuous_interpolation(melody, final_timbre)\n",
        "\n",
        "  def cycle_reconstruct(self, audio, intermediate_melody):\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "      return self.get_finetuned_file_api([audio], tmpdir)\\\n",
        "                 .cycle_reconstruct(audio, intermediate_melody)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ae = TunedAEFileApi(model_dir)\n",
        "audio_synth = ae.transfer(melody, timbre)\n",
        "play(audio_synth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTweGmVOryNA"
      },
      "source": [
        "from scipy.io import wavfile\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "wavfile.write(f\"{output_path}/audio_synth.wav\", 16000, audio_synth.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}